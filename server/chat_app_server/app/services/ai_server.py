"""
AIæœåŠ¡å™¨ - Pythonå®ç°
å¯¹åº”TypeScriptä¸­çš„AiServerç±»
"""
import logging
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime

from .ai_client import AiClient
from .ai_request_handler import AiModelConfig, Message, CallbackType
from .message_manager import MessageManager
from .tool_result_processor import ToolResultProcessor
from .mcp_tool_execute import McpToolExecute

logger = logging.getLogger(__name__)


class AiServer:
    """
    AIæœåŠ¡å™¨
    è´Ÿè´£åè°ƒAIå®¢æˆ·ç«¯ã€æ¶ˆæ¯ç®¡ç†å™¨ã€å·¥å…·æ‰§è¡Œå™¨ç­‰ç»„ä»¶
    """
    
    def __init__(
        self,
        database_service,
        mcp_tool_execute: Optional[McpToolExecute] = None
    ):
        self.database_service = database_service
        self.message_manager = MessageManager(database_service)
        self.mcp_tool_execute = mcp_tool_execute or McpToolExecute()
        
        # AIå®¢æˆ·ç«¯å°†åœ¨éœ€è¦æ—¶åˆ›å»º
        self.ai_client: Optional[AiClient] = None
        self.tool_result_processor: Optional[ToolResultProcessor] = None
        
        # å›è°ƒå‡½æ•°
        self.callback: Optional[Callable] = None
        
    def set_callback(self, callback: Callable) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self.callback = callback
        
    def _create_ai_client(
        self, 
        model_config: AiModelConfig,
        messages: List[Message],
        conversation_id: str,
        tools: List[Any],
        callback: Callable[[CallbackType, Any], None]
    ) -> AiClient:
        """åˆ›å»ºAIå®¢æˆ·ç«¯"""
        ai_client = AiClient(
            messages=messages,
            conversation_id=conversation_id,
            tools=tools,
            model_config=model_config,
            callback=callback,
            mcp_tool_execute=self.mcp_tool_execute
        )
        
        # åˆ›å»ºå·¥å…·ç»“æœå¤„ç†å™¨
        self.tool_result_processor = ToolResultProcessor(ai_client)
        
        return ai_client
    
    def send_message_sync(
        self,
        session_id: str,
        content: str,
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> Message:
        """
        å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            content: æ¶ˆæ¯å†…å®¹
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
            
        Returns:
            ä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯
        """
        try:
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            user_message_data = {
                "session_id": session_id,
                "role": "user",
                "content": content,
                "status": "completed",
                "created_at": datetime.now()
            }
            
            user_message = self.message_manager.save_user_message_sync(user_message_data)
            
            # è°ƒç”¨sendMessageDirectå¤„ç†AIå“åº”ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            self.send_message_direct_sync(
                session_id=session_id,
                messages=[{
                    "role": "user",
                    "content": content
                }],
                model_config=model_config,
                callback=callback
            )
            
            return user_message
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message_sync: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise

    async def send_message(
        self,
        session_id: str,
        content: str,
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> Message:
        """
        å‘é€æ¶ˆæ¯
        
        Args:
            session_id: ä¼šè¯ID
            content: æ¶ˆæ¯å†…å®¹
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
            
        Returns:
            ä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯
        """
        try:
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            user_message_data = {
                "session_id": session_id,
                "role": "user",
                "content": content,
                "status": "completed",
                "created_at": datetime.now()
            }
            
            user_message = await self.message_manager.save_user_message(user_message_data)
            
            # è°ƒç”¨sendMessageDirectå¤„ç†AIå“åº”
            await self.send_message_direct(
                session_id=session_id,
                messages=[{
                    "role": "user",
                    "content": content
                }],
                model_config=model_config,
                callback=callback
            )
            
            return user_message
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise
    
    async def send_message_direct(
        self,
        session_id: str,
        messages: List[Dict[str, Any]],
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> None:
        """
        ç›´æ¥å‘é€æ¶ˆæ¯ï¼ˆä¸ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
        """
        try:
            # åˆ›å»ºæ¨¡å‹é…ç½®
            if model_config:
                ai_model_config = AiModelConfig(
                    model_name=model_config.get("model_name", "gpt-3.5-turbo"),
                    temperature=model_config.get("temperature", 0.7),
                    max_tokens=model_config.get("max_tokens", 1000),
                    api_key=model_config.get("api_key", ""),
                    base_url=model_config.get("base_url", "https://api.openai.com/v1")
                )
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                ai_model_config = AiModelConfig()
            
            # è®¾ç½®å›è°ƒå‡½æ•°
            effective_callback = callback or self.callback
            
            # åˆ›å»ºå†…éƒ¨å›è°ƒå‡½æ•°æ¥å¤„ç†å„ç§äº‹ä»¶
            async def internal_callback_async(callback_type: str, data: Any):
                try:
                    if callback_type == "chunk":
                        # å¤„ç†æ–‡æœ¬å—
                        if effective_callback:
                            effective_callback("chunk", data)
                    
                    elif callback_type == "tool_call":
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        if effective_callback:
                            effective_callback("tool_call", data)
                    
                    elif callback_type == "tool_result":
                        # å¤„ç†å·¥å…·ç»“æœ
                        tool_call_id = data.get("tool_call_id")
                        result = data.get("result")
                        
                        # ä½¿ç”¨å·¥å…·ç»“æœå¤„ç†å™¨å¤„ç†ç»“æœ
                        if self.tool_result_processor and result:
                            processed_result = await self.tool_result_processor.process_tool_result(
                                tool_call_id=tool_call_id,
                                tool_name=data.get("tool_name", "unknown"),
                                result=result,
                                callback=effective_callback
                            )
                            
                            # æ›´æ–°ç»“æœ
                            data["result"] = processed_result
                        
                        if effective_callback:
                            effective_callback("tool_result", data)
                    
                    elif callback_type == "tool_stream_chunk":
                        # å¤„ç†å·¥å…·æµå¼å—
                        if effective_callback:
                            effective_callback("tool_stream_chunk", data)
                    
                    elif callback_type == "complete":
                        # å¤„ç†å®Œæˆäº‹ä»¶
                        assistant_message = data.get("message")
                        
                        if assistant_message:
                            # æ„å»ºå·¥å…·è°ƒç”¨æ•°æ®
                            tool_calls_data = []
                            if assistant_message.tool_calls:
                                for tc in assistant_message.tool_calls:
                                    tool_call_data = {
                                        "id": tc.get("id") if isinstance(tc, dict) else tc.id,
                                        "type": tc.get("type", "function") if isinstance(tc, dict) else tc.type,
                                        "function": {
                                            "name": tc.get("function", {}).get("name") if isinstance(tc, dict) else tc.function.name,
                                            "arguments": tc.get("function", {}).get("arguments") if isinstance(tc, dict) else tc.function.arguments
                                        }
                                    }
                                    # åªæœ‰åœ¨æœ‰ç»“æœæ—¶æ‰æ·»åŠ resultå­—æ®µ
                                    if isinstance(tc, dict) and tc.get("result"):
                                        tool_call_data["result"] = tc.get("result")
                                    elif hasattr(tc, 'result') and tc.result:
                                        tool_call_data["result"] = tc.result
                                    
                                    tool_calls_data.append(tool_call_data)
                            
                            # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                            assistant_message_data = {
                                "session_id": session_id,
                                "role": "assistant",
                                "content": assistant_message.content,
                                "status": "completed",
                                "created_at": datetime.now(),
                                "metadata": {
                                    "tool_calls": tool_calls_data
                                },
                                "tool_calls": tool_calls_data  # åŒæ—¶ä¿å­˜åœ¨tool_callså­—æ®µä¸­
                            }
                            
                            logger.info(f"ğŸ”§ [DEBUG] Saving assistant message with {len(tool_calls_data)} tool calls")
                            saved_message = await self.message_manager.save_assistant_message(assistant_message_data)
                            
                            # æ›´æ–°æ•°æ®ä¸­çš„æ¶ˆæ¯
                            data["message"] = saved_message
                        
                        if effective_callback:
                            effective_callback("complete", data)
                    
                    elif callback_type == "error":
                        # å¤„ç†é”™è¯¯
                        if effective_callback:
                            effective_callback("error", data)
                    
                    elif callback_type == "summary_chunk":
                        # å¤„ç†æ‘˜è¦å—ï¼ˆæ¥è‡ªå·¥å…·ç»“æœå¤„ç†å™¨ï¼‰
                        if effective_callback:
                            effective_callback("summary_chunk", data)
                    
                    else:
                        # å…¶ä»–ç±»å‹çš„å›è°ƒ
                        if effective_callback:
                            effective_callback(callback_type, data)
                            
                except Exception as e:
                    logger.error(f"Error in internal callback: {e}")
                    if effective_callback:
                            effective_callback("error", {"error": str(e)})
            
            # åˆ›å»ºåŒæ­¥åŒ…è£…å™¨
            def internal_callback(callback_type: str, data: Any):
                """åŒæ­¥åŒ…è£…å™¨ï¼Œç”¨äºè°ƒåº¦å¼‚æ­¥å›è°ƒ"""
                import asyncio
                try:
                    # è·å–å½“å‰äº‹ä»¶å¾ªç¯
                    loop = asyncio.get_event_loop()
                    # åˆ›å»ºä»»åŠ¡ä½†ä¸ç­‰å¾…
                    loop.create_task(internal_callback_async(callback_type, data))
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
                    asyncio.create_task(internal_callback_async(callback_type, data))
                except Exception as e:
                    logger.error(f"Error scheduling async callback: {e}")
            
            # å°†å­—å…¸æ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºMessageå¯¹è±¡
            message_objects = []
            for msg_dict in messages:
                message_obj = Message(
                    role=msg_dict.get("role", "user"),
                    content=msg_dict.get("content", ""),
                    session_id=session_id
                )
                message_objects.append(message_obj)
            
            # è·å–å¯ç”¨å·¥å…·
            available_tools = self.get_available_tools()
            
            # åˆ›å»ºAIå®¢æˆ·ç«¯
            self.ai_client = self._create_ai_client(
                model_config=ai_model_config,
                messages=message_objects,
                conversation_id=session_id,
                tools=available_tools,
                callback=internal_callback
            )
            
            # å¯åŠ¨AIå®¢æˆ·ç«¯
            await self.ai_client.start()
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message_direct: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise
    
    def send_message_direct_sync(
        self,
        session_id: str,
        messages: List[Dict[str, Any]],
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> None:
        """
        ç›´æ¥å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œä¸ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
        """
        try:
            # åˆ›å»ºæ¨¡å‹é…ç½®
            if model_config:
                ai_model_config = AiModelConfig(
                    model_name=model_config.get("model_name", "gpt-3.5-turbo"),
                    temperature=model_config.get("temperature", 0.7),
                    max_tokens=model_config.get("max_tokens", 1000),
                    api_key=model_config.get("api_key", ""),
                    base_url=model_config.get("base_url", "https://api.openai.com/v1")
                )
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                ai_model_config = AiModelConfig()
            
            # è®¾ç½®å›è°ƒå‡½æ•°
            effective_callback = callback or self.callback
            
            # åˆ›å»ºå†…éƒ¨å›è°ƒå‡½æ•°æ¥å¤„ç†å„ç§äº‹ä»¶ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            def internal_callback(callback_type: str, data: Any):
                try:
                    if callback_type == "chunk":
                        # å¤„ç†æ–‡æœ¬å—
                        if effective_callback:
                            effective_callback("chunk", data)
                    
                    elif callback_type == "tool_call":
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        if effective_callback:
                            effective_callback("tool_call", data)
                    
                    elif callback_type == "tool_result":
                        # å¤„ç†å·¥å…·ç»“æœ
                        tool_call_id = data.get("tool_call_id")
                        result = data.get("result")
                        
                        # ä½¿ç”¨å·¥å…·ç»“æœå¤„ç†å™¨å¤„ç†ç»“æœï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
                        if self.tool_result_processor and result:
                            processed_result = self.tool_result_processor.process_tool_result_sync(
                                tool_call_id=tool_call_id,
                                tool_name=data.get("tool_name", "unknown"),
                                result=result,
                                callback=effective_callback
                            )
                            
                            # æ›´æ–°ç»“æœ
                            data["result"] = processed_result
                        
                        if effective_callback:
                            effective_callback("tool_result", data)
                    
                    elif callback_type == "tool_stream_chunk":
                        # å¤„ç†å·¥å…·æµå¼å—
                        if effective_callback:
                            effective_callback("tool_stream_chunk", data)
                    
                    elif callback_type == "complete":
                        # å¤„ç†å®Œæˆäº‹ä»¶
                        assistant_message = data.get("message")
                        
                        if assistant_message:
                            # æ„å»ºå·¥å…·è°ƒç”¨æ•°æ®
                            tool_calls_data = []
                            if assistant_message.tool_calls:
                                for tc in assistant_message.tool_calls:
                                    tool_call_data = {
                                        "id": tc.get("id") if isinstance(tc, dict) else tc.id,
                                        "type": tc.get("type", "function") if isinstance(tc, dict) else tc.type,
                                        "function": {
                                            "name": tc.get("function", {}).get("name") if isinstance(tc, dict) else tc.function.name,
                                            "arguments": tc.get("function", {}).get("arguments") if isinstance(tc, dict) else tc.function.arguments
                                        }
                                    }
                                    # åªæœ‰åœ¨æœ‰ç»“æœæ—¶æ‰æ·»åŠ resultå­—æ®µ
                                    if isinstance(tc, dict) and tc.get("result"):
                                        tool_call_data["result"] = tc.get("result")
                                    elif hasattr(tc, 'result') and tc.result:
                                        tool_call_data["result"] = tc.result
                                    
                                    tool_calls_data.append(tool_call_data)
                            
                            # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
                            assistant_message_data = {
                                "session_id": session_id,
                                "role": "assistant",
                                "content": assistant_message.content,
                                "status": "completed",
                                "created_at": datetime.now(),
                                "metadata": {
                                    "tool_calls": tool_calls_data
                                },
                                "tool_calls": tool_calls_data  # åŒæ—¶ä¿å­˜åœ¨tool_callså­—æ®µä¸­
                            }
                            
                            logger.info(f"ğŸ”§ [DEBUG] Saving assistant message with {len(tool_calls_data)} tool calls")
                            saved_message = self.message_manager.save_assistant_message_sync(assistant_message_data)
                            
                            # æ›´æ–°æ•°æ®ä¸­çš„æ¶ˆæ¯
                            data["message"] = saved_message
                        
                        if effective_callback:
                            effective_callback("complete", data)
                    
                    elif callback_type == "error":
                        # å¤„ç†é”™è¯¯
                        if effective_callback:
                            effective_callback("error", data)
                    
                    elif callback_type == "summary_chunk":
                        # å¤„ç†æ‘˜è¦å—ï¼ˆæ¥è‡ªå·¥å…·ç»“æœå¤„ç†å™¨ï¼‰
                        if effective_callback:
                            effective_callback("summary_chunk", data)
                    
                    else:
                        # å…¶ä»–ç±»å‹çš„å›è°ƒ
                        if effective_callback:
                            effective_callback(callback_type, data)
                            
                except Exception as e:
                    logger.error(f"Error in internal callback: {e}")
                    if effective_callback:
                        effective_callback("error", {"error": str(e)})
            
            # å°†å­—å…¸æ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºMessageå¯¹è±¡
            message_objects = []
            for msg_dict in messages:
                message_obj = Message(
                    role=msg_dict.get("role", "user"),
                    content=msg_dict.get("content", ""),
                    session_id=session_id
                )
                message_objects.append(message_obj)
            
            # è·å–å¯ç”¨å·¥å…·
            available_tools = self.get_available_tools()
            
            # åˆ›å»ºAIå®¢æˆ·ç«¯
            self.ai_client = self._create_ai_client(
                model_config=ai_model_config,
                messages=message_objects,
                conversation_id=session_id,
                tools=available_tools,
                callback=internal_callback
            )
            
            # å¯åŠ¨AIå®¢æˆ·ç«¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            self.ai_client.start_sync()
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message_direct_sync: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise
    
    def abort_request(self) -> None:
        """ä¸­æ­¢å½“å‰è¯·æ±‚"""
        logger.info("ğŸ›‘ [DEBUG] AiServer.abort_request è¢«è°ƒç”¨")
        if self.ai_client:
            logger.info(f"ğŸ›‘ [DEBUG] ai_clientå­˜åœ¨ï¼Œç±»å‹: {type(self.ai_client)}")
            self.ai_client.abort()
            logger.info("ğŸ›‘ [DEBUG] AI request aborted")
        else:
            logger.warning("ğŸ›‘ [DEBUG] ai_clientä¸ºNoneï¼Œæ— æ³•ä¸­æ­¢è¯·æ±‚")
    
    def is_request_aborted(self) -> bool:
        """æ£€æŸ¥è¯·æ±‚æ˜¯å¦è¢«ä¸­æ­¢"""
        if self.ai_client:
            return self.ai_client.is_request_aborted()
        return False
    
    def reset_abort_state(self) -> None:
        """é‡ç½®ä¸­æ­¢çŠ¶æ€"""
        if self.ai_client:
            self.ai_client.reset_abort_state()
    
    def get_available_tools(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return self.mcp_tool_execute.get_tools()
    
    def get_servers_info(self) -> List[Dict[str, Any]]:
        """è·å–MCPæœåŠ¡å™¨ä¿¡æ¯"""
        return self.mcp_tool_execute.get_servers_info()
    
    async def get_session_messages(self, session_id: str) -> List[Message]:
        """è·å–ä¼šè¯æ¶ˆæ¯"""
        try:
            messages_data = await self.database_service.get_messages_by_session(session_id)
            
            messages = []
            for msg_data in messages_data:
                message = Message(
                    id=msg_data.get('id'),
                    session_id=msg_data.get('session_id'),
                    role=msg_data.get('role'),
                    content=msg_data.get('content'),
                    status=msg_data.get('status', 'completed'),
                    created_at=msg_data.get('created_at'),
                    metadata=msg_data.get('metadata'),
                    tool_calls=msg_data.get('tool_calls')
                )
                messages.append(message)
            
            return messages
            
        except Exception as e:
            logger.error(f"Error getting session messages: {e}")
            return []
    
    def clear_message_cache(self) -> None:
        """æ¸…é™¤æ¶ˆæ¯ç¼“å­˜"""
        self.message_manager.clear_cache()
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.message_manager.get_cache_stats()