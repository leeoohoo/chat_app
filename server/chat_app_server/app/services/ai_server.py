"""
AIæœåŠ¡å™¨ - Pythonå®ç°
å¯¹åº”TypeScriptä¸­çš„AiServerç±»
"""
import logging
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime

from .ai_client import AiClient
from .ai_request_handler import AiModelConfig, Message, CallbackType
from .message_manager import MessageManager
from .tool_result_processor import ToolResultProcessor
from .mcp_tool_execute import McpToolExecute
from ..models.message import MessageCreate

logger = logging.getLogger(__name__)


class AiServer:
    """
    AIæœåŠ¡å™¨
    è´Ÿè´£åè°ƒAIå®¢æˆ·ç«¯ã€æ¶ˆæ¯ç®¡ç†å™¨ã€å·¥å…·æ‰§è¡Œå™¨ç­‰ç»„ä»¶
    """
    
    def __init__(
        self,
        database_service=None,  # ä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸å†ä½¿ç”¨
        mcp_tool_execute: Optional[McpToolExecute] = None
    ):
        self.database_service = database_service  # ä¿æŒå…¼å®¹æ€§
        self.message_manager = MessageManager()  # ä¸å†ä¼ é€’ database_service
        self.mcp_tool_execute = mcp_tool_execute or McpToolExecute()
        
        # AIå®¢æˆ·ç«¯å°†åœ¨éœ€è¦æ—¶åˆ›å»º
        self.ai_client: Optional[AiClient] = None
        self.tool_result_processor: Optional[ToolResultProcessor] = None
        
        # å›è°ƒå‡½æ•°
        self.callback: Optional[Callable] = None
        
    def set_callback(self, callback: Callable) -> None:
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self.callback = callback
        
    def _create_ai_client(
        self, 
        model_config: AiModelConfig,
        messages: List[Message],
        conversation_id: str,
        tools: List[Any],
        callback: Callable[[CallbackType, Any], None]
    ) -> AiClient:
        """åˆ›å»ºAIå®¢æˆ·ç«¯"""
        ai_client = AiClient(
            messages=messages,
            conversation_id=conversation_id,
            tools=tools,
            model_config=model_config,
            callback=callback,
            mcp_tool_execute=self.mcp_tool_execute,
            message_manager=self.message_manager
        )
        
        # åˆ›å»ºå·¥å…·ç»“æœå¤„ç†å™¨
        self.tool_result_processor = ToolResultProcessor(ai_client)
        
        return ai_client
    
    def send_message_sync(
        self,
        session_id: str,
        content: str,
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> Message:
        """
        å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            content: æ¶ˆæ¯å†…å®¹
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
            
        Returns:
            ä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯
        """
        try:
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            user_message_data = {
                "session_id": session_id,
                "role": "user",
                "content": content,
                "status": "completed",
                "created_at": datetime.now()
            }
            
            user_message = self.message_manager.save_user_message_sync(user_message_data)
            
            # è°ƒç”¨sendMessageDirectå¤„ç†AIå“åº”ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            self.send_message_direct_sync(
                session_id=session_id,
                messages=[{
                    "role": "user",
                    "content": content
                }],
                model_config=model_config,
                callback=callback
            )
            
            return user_message
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message_sync: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise

    def send_message_direct_sync(
        self,
        session_id: str,
        messages: List[Dict[str, Any]],
        model_config: Optional[Dict[str, Any]] = None,
        callback: Optional[Callable] = None
    ) -> None:
        """
        ç›´æ¥å‘é€æ¶ˆæ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œä¸ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            model_config: æ¨¡å‹é…ç½®
            callback: å›è°ƒå‡½æ•°
        """
        try:
            # åˆ›å»ºæ¨¡å‹é…ç½®
            if model_config:
                ai_model_config = AiModelConfig(
                    model_name=model_config.get("model_name", "gpt-3.5-turbo"),
                    temperature=model_config.get("temperature", 0.7),
                    max_tokens=model_config.get("max_tokens", 1000),
                    api_key=model_config.get("api_key", ""),
                    base_url=model_config.get("base_url", "https://api.openai.com/v1")
                )
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                ai_model_config = AiModelConfig()
            
            # è®¾ç½®å›è°ƒå‡½æ•°
            effective_callback = callback or self.callback
            
            # åˆ›å»ºå†…éƒ¨å›è°ƒå‡½æ•°æ¥å¤„ç†å„ç§äº‹ä»¶ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            def internal_callback(callback_type: str, data: Any):
                try:
                    if callback_type == "chunk":
                        # å¤„ç†æ–‡æœ¬å—
                        if effective_callback:
                            effective_callback("chunk", data)
                    
                    elif callback_type == "tool_call":
                        # å¤„ç†å·¥å…·è°ƒç”¨
                        if effective_callback:
                            effective_callback("tool_call", data)
                    
                    elif callback_type == "tool_result":
                        # å¤„ç†å·¥å…·ç»“æœ - å·¥å…·æ¶ˆæ¯ä¿å­˜ç°åœ¨åœ¨AiClientä¸­å¤„ç†
                        tool_call_id = data.get("tool_call_id")
                        result = data.get("result")
                        tool_name = data.get("tool_name", "unknown")
                        
                        # ä½¿ç”¨å·¥å…·ç»“æœå¤„ç†å™¨å¤„ç†ç»“æœï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
                        if self.tool_result_processor and result:
                            processed_result = self.tool_result_processor.process_tool_result_sync(
                                tool_call_id=tool_call_id,
                                tool_name=tool_name,
                                result=result,
                                callback=effective_callback
                            )
                            
                            # æ›´æ–°ç»“æœ
                            data["result"] = processed_result
                            result = processed_result
                        
                        # å·¥å…·æ¶ˆæ¯ä¿å­˜å·²ç»åœ¨AiClientä¸­å¤„ç†ï¼Œè¿™é‡Œåªéœ€è¦è½¬å‘å›è°ƒ
                        if effective_callback:
                            effective_callback("tool_result", data)
                    
                    elif callback_type == "tool_stream_chunk":
                        # å¤„ç†å·¥å…·æµå¼å—
                        if effective_callback:
                            effective_callback("tool_stream_chunk", data)
                    
                    elif callback_type == "complete":
                        # å¤„ç†å®Œæˆäº‹ä»¶ - æ¶ˆæ¯å·²ç»åœ¨AiRequestHandlerä¸­ä¿å­˜äº†
                        logger.info("ğŸ¯ AI response completed - message already saved by AiRequestHandler")
                        
                        if effective_callback:
                            effective_callback("complete", data)
                    
                    elif callback_type == "error":
                        # å¤„ç†é”™è¯¯
                        if effective_callback:
                            effective_callback("error", data)
                    
                    elif callback_type == "summary_chunk":
                        # å¤„ç†æ‘˜è¦å—ï¼ˆæ¥è‡ªå·¥å…·ç»“æœå¤„ç†å™¨ï¼‰
                        if effective_callback:
                            effective_callback("summary_chunk", data)
                    
                    else:
                        # å…¶ä»–ç±»å‹çš„å›è°ƒ
                        if effective_callback:
                            effective_callback(callback_type, data)
                            
                except Exception as e:
                    logger.error(f"Error in internal callback: {e}")
                    if effective_callback:
                        effective_callback("error", {"error": str(e)})
            
            # å°†å­—å…¸æ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºMessageå¯¹è±¡
            message_objects = []
            for msg_dict in messages:
                message_obj = Message(
                    role=msg_dict.get("role", "user"),
                    content=msg_dict.get("content", ""),
                    session_id=session_id
                )
                message_objects.append(message_obj)
            
            # è·å–å¯ç”¨å·¥å…·
            available_tools = self.get_available_tools()
            
            # åˆ›å»ºAIå®¢æˆ·ç«¯
            self.ai_client = self._create_ai_client(
                model_config=ai_model_config,
                messages=message_objects,
                conversation_id=session_id,
                tools=available_tools,
                callback=internal_callback
            )
            
            # å¯åŠ¨AIå®¢æˆ·ç«¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            self.ai_client.start_sync()
            
        except Exception as e:
            import traceback
            error_details = f"Error in send_message_direct_sync: {str(e)}\nTraceback: {traceback.format_exc()}"
            logger.error(error_details)
            if callback:
                callback("error", {"error": str(e)})
            raise
    
    def abort_request(self) -> None:
        """ä¸­æ­¢å½“å‰è¯·æ±‚"""
        logger.info("ğŸ›‘ [DEBUG] AiServer.abort_request è¢«è°ƒç”¨")
        if self.ai_client:
            logger.info(f"ğŸ›‘ [DEBUG] ai_clientå­˜åœ¨ï¼Œç±»å‹: {type(self.ai_client)}")
            self.ai_client.abort()
            logger.info("ğŸ›‘ [DEBUG] AI request aborted")
        else:
            logger.warning("ğŸ›‘ [DEBUG] ai_clientä¸ºNoneï¼Œæ— æ³•ä¸­æ­¢è¯·æ±‚")
    
    def is_request_aborted(self) -> bool:
        """æ£€æŸ¥è¯·æ±‚æ˜¯å¦è¢«ä¸­æ­¢"""
        if self.ai_client:
            return self.ai_client.is_request_aborted()
        return False
    
    def reset_abort_state(self) -> None:
        """é‡ç½®ä¸­æ­¢çŠ¶æ€"""
        if self.ai_client:
            self.ai_client.reset_abort_state()
    
    def get_available_tools(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return self.mcp_tool_execute.get_tools()
    
    def get_servers_info(self) -> List[Dict[str, Any]]:
        """è·å–MCPæœåŠ¡å™¨ä¿¡æ¯"""
        return self.mcp_tool_execute.get_servers_info()
    
    async def get_session_messages(self, session_id: str) -> List[Message]:
        """è·å–ä¼šè¯æ¶ˆæ¯"""
        try:
            messages_data = await MessageCreate.get_by_session(session_id)
            
            messages = []
            for msg_data in messages_data:
                message = Message(
                    id=msg_data.get('id'),
                    session_id=msg_data.get('session_id'),
                    role=msg_data.get('role'),
                    content=msg_data.get('content'),
                    status=msg_data.get('status', 'completed'),
                    created_at=msg_data.get('created_at'),
                    metadata=msg_data.get('metadata'),
                    tool_calls=msg_data.get('tool_calls')
                )
                messages.append(message)
            
            return messages
            
        except Exception as e:
            logger.error(f"Error getting session messages: {e}")
            return []
    
    def clear_message_cache(self) -> None:
        """æ¸…é™¤æ¶ˆæ¯ç¼“å­˜"""
        self.message_manager.clear_cache()
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.message_manager.get_cache_stats()