# AI è¯·æ±‚ä»£ç†æ¨¡å—
# ä½¿ç”¨ OpenAI Python SDK å¤„ç†è¯·æ±‚

import asyncio
import json
import logging
import time
import uuid
from typing import Dict, Any, Optional, AsyncGenerator
from fastapi import Request, Response, HTTPException
from fastapi.responses import StreamingResponse
import openai
from openai import AsyncOpenAI
from app.services.stream_manager import stream_manager

logger = logging.getLogger(__name__)

async def handle_chat_proxy(request: Request, body: Dict[str, Any]) -> Response:
    """
    é€šç”¨ AI API ä»£ç†å¤„ç†å™¨
    ä½¿ç”¨ OpenAI SDK å¤„ç†è¯·æ±‚ï¼Œæ”¯æŒå¤šç§ AI æœåŠ¡æä¾›å•†
    æ”¯æŒä¸¤ç§æ¨¡å¼:
    1. OpenAIå®¢æˆ·ç«¯æ¨¡å¼: ä½¿ç”¨Authorizationå¤´éƒ¨å’Œx-target-urlå¤´éƒ¨
    2. è‡ªå®šä¹‰å¤´éƒ¨æ¨¡å¼: ä½¿ç”¨x-base-urlå’Œx-api-keyå¤´éƒ¨
    """
    try:
        messages = body.get('messages', [])
        model = body.get('model', 'gpt-3.5-turbo')
        stream = body.get('stream', True)
        session_id = body.get('session_id', str(uuid.uuid4()))
        
        logger.info(f'ğŸ¤– é€šç”¨AIä»£ç†è¯·æ±‚: {request.method}')
        logger.info(f'Headers: Authorization={bool(request.headers.get("authorization"))}, '
                   f'x-target-url={bool(request.headers.get("x-target-url"))}, '
                   f'x-base-url={bool(request.headers.get("x-base-url"))}, '
                   f'x-api-key={bool(request.headers.get("x-api-key"))}')

        base_url, api_key = None, None

        # æ¨¡å¼1: OpenAIå®¢æˆ·ç«¯æ¨¡å¼ (ä¼˜å…ˆ)
        if request.headers.get('authorization') and request.headers.get('x-target-url'):
            base_url = request.headers.get('x-target-url')
            api_key = request.headers.get('authorization').replace('Bearer ', '')
            logger.info('ğŸ”§ ä½¿ç”¨OpenAIå®¢æˆ·ç«¯æ¨¡å¼')
        # æ¨¡å¼2: è‡ªå®šä¹‰å¤´éƒ¨æ¨¡å¼
        elif request.headers.get('x-base-url') and request.headers.get('x-api-key'):
            base_url = request.headers.get('x-base-url')
            api_key = request.headers.get('x-api-key')
            logger.info('ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰å¤´éƒ¨æ¨¡å¼')
        # æ¨¡å¼3: ç›´æ¥ä»Authorizationå¤´éƒ¨æå–ï¼Œä½¿ç”¨é»˜è®¤ç›®æ ‡URL
        elif request.headers.get('authorization'):
            base_url = 'https://api.openai.com/v1'  # é»˜è®¤OpenAI API
            api_key = request.headers.get('authorization').replace('Bearer ', '')
            logger.info(f'ğŸ”§ ä½¿ç”¨é»˜è®¤ç›®æ ‡URLæ¨¡å¼: {base_url}')
        else:
            raise HTTPException(
                status_code=400,
                detail={
                    'error': 'ç¼ºå°‘å¿…éœ€çš„è®¤è¯ä¿¡æ¯ã€‚è¯·æä¾›ä»¥ä¸‹ä»»ä¸€ç»„åˆ:\n'
                           '1. Authorization + x-target-url å¤´éƒ¨\n'
                           '2. x-base-url + x-api-key å¤´éƒ¨\n'
                           '3. ä»… Authorization å¤´éƒ¨ï¼ˆä½¿ç”¨é»˜è®¤ç›®æ ‡ï¼‰',
                    'code': 'MISSING_AUTH_INFO'
                }
            )

        logger.info(f'ğŸš€ ä½¿ç”¨OpenAI SDKè¯·æ±‚: {base_url}')
        
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url
        )

        # æ£€æŸ¥æ˜¯å¦æ˜¯æµå¼è¯·æ±‚
        is_stream_request = body.get('stream', False)
        
        if is_stream_request:
            logger.info(f"ğŸ“¡ å¤„ç†æµå¼è¯·æ±‚ï¼Œä¼šè¯ID: {session_id}")
            
            # åˆ›å»ºæµå¼å“åº”
            async def stream_generator():
                try:
                    # åˆ›å»ºæµå¼è¯·æ±‚
                    # è¿‡æ»¤æ‰session_idå’Œstreamå‚æ•°ï¼Œç„¶åæ˜¾å¼è®¾ç½®stream=True
                    filtered_body = {k: v for k, v in body.items() if k not in ['session_id', 'stream']}
                    stream_response = await client.chat.completions.create(
                        **filtered_body,
                        stream=True
                    )
                    
                    async for chunk in stream_response:
                        # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
                        if not stream_manager.is_stream_active(session_id):
                            logger.info(f"ğŸ›‘ æµå¼è¯·æ±‚è¢«ä¸­æ–­ï¼Œä¼šè¯ID: {session_id}")
                            break
                        
                        data = f"data: {json.dumps(chunk.model_dump())}\n\n"
                        yield data
                    
                    # å‘é€å®Œæˆä¿¡å·
                    if stream_manager.is_stream_active(session_id):
                        yield "data: [DONE]\n\n"
                        logger.info(f"âœ… æµå¼è¯·æ±‚å¤„ç†å®Œæˆï¼Œä¼šè¯ID: {session_id}")
                    
                except asyncio.CancelledError:
                    logger.info(f"ğŸ›‘ æµå¼è¯·æ±‚è¢«ç”¨æˆ·ä¸­æ–­ï¼Œä¼šè¯ID: {session_id}")
                    raise
                except Exception as error:
                    logger.error(f"âŒ æµå¼è¯·æ±‚å¤„ç†å¤±è´¥ï¼Œä¼šè¯ID: {session_id}: {error}")
                    if stream_manager.is_stream_active(session_id):
                        yield f"data: {json.dumps({'error': str(error)})}\n\n"
                finally:
                    # ç¡®ä¿ä¼šè¯è¢«æ¸…ç†
                    await stream_manager.unregister_stream(session_id)
            
            # åˆ›å»ºæµå¼å“åº”
            response = StreamingResponse(
                stream_generator(),
                media_type="text/plain",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Headers": "*",
                    "X-Session-Id": session_id
                }
            )
            
            # æ³¨å†Œåˆ°æµå¼ä¼šè¯ç®¡ç†å™¨
            task = asyncio.current_task()
            await stream_manager.register_stream(
                session_id, 
                response, 
                task,
                {
                    'model': body.get('model'),
                    'messageCount': len(body.get('messages', [])),
                    'userAgent': request.headers.get('user-agent')
                }
            )
            
            return response
            
        else:
            logger.info('ğŸ“¡ å¤„ç†éæµå¼è¯·æ±‚')
            
            try:
                # ä½¿ç”¨ OpenAI SDK å‘é€éæµå¼è¯·æ±‚
                # è¿‡æ»¤æ‰session_idå’Œstreamå‚æ•°ï¼Œç„¶åæ˜¾å¼è®¾ç½®stream=False
                filtered_body = {k: v for k, v in body.items() if k not in ['session_id', 'stream']}
                response = await client.chat.completions.create(
                    **filtered_body,
                    stream=False
                )

                logger.info('âœ… AIä»£ç†è¯·æ±‚æˆåŠŸï¼Œè¿”å›JSONæ•°æ®')
                return Response(
                    content=response.model_dump_json(),
                    media_type="application/json"
                )
                
            except Exception as error:
                logger.error(f'âŒ API é”™è¯¯å“åº”: {error}')
                
                # å¤„ç† OpenAI SDK é”™è¯¯
                if hasattr(error, 'status_code'):
                    raise HTTPException(
                        status_code=error.status_code,
                        detail={
                            'error': str(error),
                            'code': getattr(error, 'code', 'API_ERROR'),
                            'type': getattr(error, 'type', 'unknown')
                        }
                    )
                else:
                    raise HTTPException(
                        status_code=500,
                        detail={
                            'error': 'è¯·æ±‚å¤„ç†å¤±è´¥',
                            'code': 'INTERNAL_ERROR',
                            'details': str(error)
                        }
                    )
    
    except HTTPException:
        raise
    except Exception as error:
        logger.error(f'âŒ AIä»£ç†è¯·æ±‚å¤±è´¥: {error}')
        
        # åŒºåˆ†ä¸åŒç±»å‹çš„é”™è¯¯
        if 'ENOTFOUND' in str(error) or 'ECONNREFUSED' in str(error):
            raise HTTPException(
                status_code=503,
                detail={
                    'error': 'æ— æ³•è¿æ¥åˆ°ç›®æ ‡APIæœåŠ¡',
                    'code': 'CONNECTION_ERROR',
                    'details': str(error)
                }
            )
        
        if 'timeout' in str(error).lower():
            raise HTTPException(
                status_code=408,
                detail={
                    'error': 'è¯·æ±‚è¶…æ—¶',
                    'code': 'TIMEOUT_ERROR',
                    'details': str(error)
                }
            )
        
        if 'Invalid URL' in str(error):
            raise HTTPException(
                status_code=400,
                detail={
                    'error': 'æ— æ•ˆçš„ç›®æ ‡URL',
                    'code': 'INVALID_URL',
                    'details': str(error)
                }
            )
        
        # é€šç”¨é”™è¯¯å¤„ç†
        raise HTTPException(
            status_code=500,
            detail={
                'error': 'ä»£ç†æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
                'code': 'INTERNAL_ERROR',
                'details': str(error)
            }
        )

def handle_health_check() -> Dict[str, Any]:
    """å¥åº·æ£€æŸ¥å¤„ç†å™¨"""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "proxy": {
            "type": "é€šç”¨AI APIä»£ç†",
            "description": "æ”¯æŒè½¬å‘ä»»æ„AI APIè¯·æ±‚ï¼Œå…¼å®¹OpenAIå®¢æˆ·ç«¯",
            "supported_modes": [
                {
                    "name": "OpenAIå®¢æˆ·ç«¯æ¨¡å¼",
                    "description": "ç›´æ¥å…¼å®¹OpenAI Pythonå®¢æˆ·ç«¯",
                    "usage": {
                        "baseURL": "http://localhost:3001/api/chat/completions",
                        "headers": {
                            "x-target-url": "å®é™…çš„AI APIç«¯ç‚¹URL"
                        },
                        "example": """
# Pythonç¤ºä¾‹
from openai import AsyncOpenAI

client = AsyncOpenAI(
    api_key='your-api-key',
    base_url='http://localhost:3001/api/chat',
    default_headers={
        'x-target-url': 'https://api.openai.com/v1'
    }
)"""
                    }
                },
                {
                    "name": "è‡ªå®šä¹‰å¤´éƒ¨æ¨¡å¼",
                    "description": "ä½¿ç”¨è‡ªå®šä¹‰å¤´éƒ¨è¿›è¡Œé…ç½®",
                    "usage": {
                        "endpoint": "/api/chat/completions",
                        "method": "POST",
                        "required_headers": {
                            "x-base-url": "ç›®æ ‡APIçš„å®Œæ•´URL",
                            "x-api-key": "APIå¯†é’¥"
                        }
                    }
                },
                {
                    "name": "é»˜è®¤ç›®æ ‡æ¨¡å¼",
                    "description": "ä»…æä¾›Authorizationå¤´éƒ¨ï¼Œä½¿ç”¨é»˜è®¤ç›®æ ‡URL",
                    "usage": {
                        "endpoint": "/api/chat/completions",
                        "method": "POST",
                        "required_headers": {
                            "Authorization": "Bearer your-api-key"
                        },
                        "note": "ä½¿ç”¨é»˜è®¤çš„ OpenAI API"
                    }
                }
            ]
        }
    }